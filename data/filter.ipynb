{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import enchant\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    word_list = list(set(text.split()))\n",
    "    word_list = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    word_list.sort(key=lambda w: text.index(w))\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_list(text):\n",
    "    sentences = re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_word_frequencies(data_series):\n",
    "    sentence_word_frequencies = {}\n",
    "    for i, text in data_series.items():\n",
    "        sentences = get_sentence_list(text)\n",
    "        for sentence in sentences:\n",
    "            words = get_word_list(sentence)\n",
    "            if words:\n",
    "                sentence_key = ' '.join(words)\n",
    "                if sentence_key not in sentence_word_frequencies:\n",
    "                    sentence_word_frequencies[sentence_key] = 1\n",
    "                else:\n",
    "                    sentence_word_frequencies[sentence_key] += 1\n",
    "    df = pd.DataFrame.from_dict(sentence_word_frequencies, orient='index', columns=['frequency'])\n",
    "    df.index.name = 'sentence'\n",
    "    df = df.sort_values('frequency', ascending=False)\n",
    "    df.head(20).plot(kind='bar', legend=False)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Top 20 sentence frequencies')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_punctuation(text):\n",
    "    text = re.sub(r'\\s+([?.!,;:])', r'\\1 ', text)\n",
    "    text = re.sub(r'([‘“„«])\\s+', r'\\1', text)\n",
    "    text = re.sub(r'\\s+([’”“»])', r'\\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\.(\\s*)([a-z])', lambda match: f\".{match.group(1)}{match.group(2).capitalize()}\", text)\n",
    "    dictionary = enchant.Dict(\"en_US\")\n",
    "    words = text.split()\n",
    "    corrected_text = \"\"\n",
    "    for i, word in enumerate(words):\n",
    "        if not dictionary.check(word):\n",
    "            suggestions = dictionary.suggest(word)\n",
    "            if len(suggestions) > 0:\n",
    "                corrected_word = suggestions[0]\n",
    "                pos = text.find(word)\n",
    "                prefix = text[:pos]\n",
    "                suffix = text[pos+len(word):]\n",
    "                if suffix and not suffix[0].isspace():\n",
    "                    corrected_word = f\" {corrected_word}\"\n",
    "                corrected_text += f\"{prefix}{corrected_word}{word[-1]}{suffix}\"\n",
    "            else:\n",
    "                corrected_text += f\"{word} \"\n",
    "        else:\n",
    "            corrected_text += f\"{word} \"\n",
    "    corrected_text = re.sub(r'\\s+', ' ', corrected_text.strip())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_frequency(used_word_sets):\n",
    "    new_data_series = {}\n",
    "    data_series = pd.read_json('test.json', typ='series')\n",
    "    for i, text in data_series.items():\n",
    "        word_set = set(get_word_list(data_series[i])) \n",
    "        if not word_set.issubset(used_word_sets):\n",
    "            used_word_sets.update(word_set)\n",
    "            new_data_series[i] = data_series[i]\n",
    "\n",
    "    words = [word for text in new_data_series.values() for word in word_tokenize(text)]\n",
    "    fdist = FreqDist(words)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    fdist.plot(30, cumulative=False)\n",
    "    plt.title('Top 30 Most Common Words')\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_word_sets = set()\n",
    "removed_word_set = set()\n",
    "new_data_series = {}\n",
    "data_series = pd.read_json('test.json', typ='series')\n",
    "for i, text in data_series.items():\n",
    "    data_series[i] = correct_punctuation(data_series[i])\n",
    "    word_set = set(get_word_list(data_series[i]))\n",
    "    removed_word_set.update(used_word_sets - word_set)  # cập nhật set các từ bị xóa\n",
    "    if not word_set.issubset(used_word_sets):\n",
    "        used_word_sets.update(word_set)\n",
    "        new_data_series[i] = data_series[i]\n",
    "\n",
    "data_series = pd.Series(new_data_series)\n",
    "print(f\"Số lượng bộ từ vựng bị xóa: {len(removed_word_set)}\")\n",
    "print(\"Bộ từ vựng bị xóa:\")\n",
    "print(removed_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_frequency(used_word_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
